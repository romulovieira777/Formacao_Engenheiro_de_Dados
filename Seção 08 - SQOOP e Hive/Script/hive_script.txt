#sqoop preparação
#Alterar senha do user postgres:
sudo -u postgres psql
alter user  postgres PASSWORD '123456';
#alterar arquivo de configuração do Postgres, para permitir conexão remota
sudo vi /var/lib/pgsql/11/data/pg_hba.conf
#incluir linha
host all all 0.0.0.0/0 md5
#Parar e reiniciar Postgres
sudo service postgresql-11 stop
sudo service postgresql-11 start
#driver
cd /home/cloudera/Downloads
wget http://jdbc.postgresql.org/download/postgresql-9.2-1002.jdbc4.jar
sudo cp postgresql-9.2-1002.jdbc4.jar  /var/lib/sqoop/postgresql-9.2-1002.jdbc4.jar
#listagem db
sqoop list-databases --connect jdbc:postgresql://127.0.0.1/ --username
postgres --password 123456
#listagem tabelas
sqoop list-tables --connect jdbc:postgresql://127.0.0.1/ed --username postgres --password 123456 -- --schema dimensional
#importar
sqoop import-all-tables --connect jdbc:postgresql://127.0.0.1/ed --username postgres --password 123456 -- --schema dimensional
#verifica a importação
sudo hdfs dfs -ls /user/cloudera
#abre um arquivo
sudo hdfs dfs -cat /user/cloudera/fatovendas/part-m-00000




#drop database ed cascade;
beeline
!connect jdbc:hive2://





show databases;
create database ed;
use ed;



create table dimensaocliente(chavecliente int, idcliente int, cliente string, estado char(2), sexo char(1), status string, datainiciovalidade date, datafimvalidade date) row format delimited fields terminated by ',' location '/user/cloudera/dimensaocliente/';

select * from dimensaocliente limit 10;

create table dimensaotempo(chavetempo int, data date, dia int, mes int, ano int, diasemana int, trimestre int) row format delimited fields terminated by ',' location '/user/cloudera/dimensaotempo/';

select * from dimensaotempo limit 10;


create table dimensaoproduto(chaveproduto int, idproduto int, produto string, datainiciovalidade date, datafimvalidade date) row format delimited fields terminated by ',' location '/user/cloudera/dimensaoproduto/';

select * from dimensaoproduto;

create table dimensaovendedor(chavevendedor int, idvendedor int, nome string, datainiciovalidade date, datafimvalidade date) row format delimited fields terminated by ',' location '/user/cloudera/dimensaovendedor/';

select * from dimensaovendedor;

create table fatovendas (chavevendas int, chavevendedor int, chavecliente int, chaveproduto int,  chavetempo int, quantidade int, valorunitario float, valortotal float, desconto float) row format delimited fields terminated by ',' location '/user/cloudera/fatovendas/';

select * from fatovendas limit 10;



show tables;

#verificar banco de dados criado dentro do hive
hdfs dfs -ls /user/hive/warehouse/




#hue
#Query editor/ Hive

select * from fatovendas limit 10

select sum(fatovendas.valortotal) from fatovendas 

select sum(fv.valortotal) from fatovendas fv
join dimensaovendedor dv on (dv.chavevendedor = fv.chavevendedor)
where dv.nome = 'Capitolino Bahía'


select sum(fv.valortotal) from fatovendas fv
join dimensaovendedor dv on (dv.chavevendedor = fv.chavevendedor)
join dimensaotempo dt on (fv.chavetempo = dt.chavetempo)
where dv.nome = 'Capitolino Bahía' and dt.trimestre = 1;


#criar tabela desnormalizada
#esta parte do código cria depois
create table des_vendas as 

select 
       dc.cliente,
       dc.estado,
       dc.sexo,
       dc.status,
       fv.quantidade,
       fv.valorunitario,
       fv.valortotal,
       fv.desconto,
       dp.produto,
       dt.data,
       dt.dia,
       dt.mes,
       dt.ano,
       dt.trimestre,
       dv.nome
  from dimensaocliente dc
  join fatovendas fv  on fv.chavecliente = dc.chavecliente
  join dimensaoproduto dp on dp.chaveproduto = fv.chaveproduto
  join dimensaotempo dt on dt.chavetempo = fv.chavetempo
  join dimensaovendedor dv on dv.chavevendedor = fv.chavevendedor;

#verifica a tabela criada
select count( *) from des_vendas

#exemplo arredondamento
select sum(valortotal) from des_vendas;
select round(sum(valortotal),2) from des_vendas;






#####################
#particionamento
#habilita particionamento dinamico
set hive.exec.dynamic.partition.mode=nonstrict

create table des_vendas_part(quantidade int,valortotal float ) PARTITIONED BY(estado char(2));

INSERT OVERWRITE TABLE des_vendas_part PARTITION(estado)
SELECT quantidade,valortotal,estado from  des_vendas;

#consultar des_vendas_part
select * from des_vendas_part limit 10;


#comparação de performance
#sem partição
select * from des_vendas  where estado = 'AC';
#com partição
select * from des_vendas_part  where estado = 'AC';


#olhar no hdfs
hdfs dfs -ls /user/hive/warehouse/ed.db/des_vendas_part/
hdfs dfs -ls /user/hive/warehouse/ed.db/des_vendas_part/estado=AC


######################
#bucket
create table des_vendas_buck(quantidade int,valortotal float, estado char(2) ) clustered by(estado)
into 4 buckets;



INSERT OVERWRITE TABLE des_vendas_buck 
SELECT quantidade,valortotal,estado from des_vendas;


select * from des_vendas_buck limit 10;






